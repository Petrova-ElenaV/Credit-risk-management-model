{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69fc6382-5195-4d3a-8c8f-e319c79c3790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T21:42:54.123929Z",
     "iopub.status.busy": "2025-02-17T21:42:54.122954Z",
     "iopub.status.idle": "2025-02-17T21:42:56.082022Z",
     "shell.execute_reply": "2025-02-17T21:42:56.080924Z",
     "shell.execute_reply.started": "2025-02-17T21:42:54.123896Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "import dask.dataframe as dd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import dill\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b090daf-a44d-4de3-9d1f-2609fd71d22b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T21:42:56.084366Z",
     "iopub.status.busy": "2025-02-17T21:42:56.083547Z",
     "iopub.status.idle": "2025-02-17T21:42:56.431673Z",
     "shell.execute_reply": "2025-02-17T21:42:56.430776Z",
     "shell.execute_reply.started": "2025-02-17T21:42:56.084327Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  flag\n",
       "0   0     0\n",
       "1   1     0\n",
       "2   2     0\n",
       "3   3     0\n",
       "4   4     0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "df_target = pd.read_csv(\"train_data/train_target.csv\")\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932c1bec-b20c-445a-a831-c6ed0c1045f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T21:42:58.398974Z",
     "iopub.status.busy": "2025-02-17T21:42:58.397643Z",
     "iopub.status.idle": "2025-02-17T21:42:58.427011Z",
     "shell.execute_reply": "2025-02-17T21:42:58.426154Z",
     "shell.execute_reply.started": "2025-02-17T21:42:58.398940Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загрузим данные из файлов в датафрейм...\n",
    "# а также  все фичи развернем в столбцы, так как многочисленные эксперименты показали, что иначе т ребуемой точности не добиться...\n",
    "def read_and_prepare():\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "    df_final=pd.DataFrame()\n",
    "    for i in range(0, 12):\n",
    "        file_path = \"train_data/train_data_\"+str(i)+\".pq\"\n",
    "        df = dd.read_parquet(file_path)     \n",
    "        df = df.compute()\n",
    "        print(\"Количество пропусков в файле \", file_path,\" \", df.columns.isna().sum())\n",
    "        all_features = df.columns.to_list()\n",
    "        all_features.remove(\"id\")\n",
    "        encoded_data  = ohe.fit_transform(df[all_features])\n",
    "        encoded_data = pd.DataFrame(encoded_data, columns=ohe.get_feature_names_out())\n",
    "        #присоединим к датафрейму закодированные фичи\n",
    "        df = pd.concat([df, encoded_data], axis=1) \n",
    "        #удалим все исходные фичи\n",
    "        df = df.drop(all_features, axis=1)\n",
    "        #сгруппируем по id клиента\n",
    "        df_agg = df.groupby('id').sum()   \n",
    "        #смержим с таргетом\n",
    "        df_agg_new = pd.merge(df_agg, df_target, on='id', how='inner')\n",
    "        #присоединим полученный датафрейм к итоговому\n",
    "        df_final =pd.concat( [df_agg_new, df_final], axis=0)\n",
    "    return df_final   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c019a7f6-2aad-46fd-8eff-134fe7dc1364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T21:42:59.238235Z",
     "iopub.status.busy": "2025-02-17T21:42:59.236913Z",
     "iopub.status.idle": "2025-02-17T21:56:21.016927Z",
     "shell.execute_reply": "2025-02-17T21:56:21.015551Z",
     "shell.execute_reply.started": "2025-02-17T21:42:59.238200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в файле  train_data/train_data_0.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_1.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_2.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_3.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_4.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_5.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_6.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_7.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_8.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_9.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_10.pq   0\n",
      "Количество пропусков в файле  train_data/train_data_11.pq   0\n",
      "[21:54:14] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = read_and_prepare()\n",
    "\n",
    "model =  XGBClassifier(n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "           ('classifier',  model)\n",
    "    ])\n",
    "\n",
    "\n",
    "pipe.fit(df_final, df_final['flag'])\n",
    "\n",
    "with open(\"ML_Final.pkl\", 'wb') as file:\n",
    "    dill.dump(\n",
    "              { \"model\": model,\n",
    "                    \"metadata\": {\n",
    "                        \"name\": \"My ML Final\",\n",
    "                        \"author\": \"Elena Petrova\",\n",
    "                        \"version\": 1,\n",
    "                        \"date\": datetime.datetime.now(),\n",
    "                        \"type\": type(pipe.named_steps[\"classifier\"]).__name__,\n",
    "                    }\n",
    "                },\n",
    "    file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee925d-2d23-48eb-89fa-274594af895c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
